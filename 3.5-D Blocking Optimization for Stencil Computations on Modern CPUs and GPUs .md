# 1. Basic Info
## 1.1 Authors
Nguyen, A.; Satish, N.; Chhugani, J.; Changkyu Kim; Dubey, P.
## 1.2 Publication
2010 ACM/IEEE International Conference for High Performance Computing, Networking, Storage and Analysis
# 2. Basic Concept
## 2.1 Stencil Computation (SC)
Stencil computation sweeps over a spatial grid over multiple time steps to perform nearest-neighbor computations.

## 2.2 Compute Bound
Ref wiki: https://en.wikipedia.org/wiki/CPU-bound. \
A computer is CPU-bound when the time for it to complete a task is determined principally by the speed of the centrl processor. \
Extension: In computer science, X-bound is the concept that performance is limited that can't be improved due to X.

## 2.3 Tranlation Look aside Buffer (TLB)
Memory instructions must go through a virtual-to-physical address translation, which is in the critical path of program execution. To improve translation speed, a TLB is used to cache virtual-to-physical translation of most frequently accessed pages. if the translation is not found in the TLB, processor pipeline stalls util the TLB miss is served.

## 2.4 Software Pipelining
Ref wiki: https://en.wikipedia.org/wiki/Software_pipelining. \
Software pipelining is a technique used to optimize loops, it is a type of out-of-order execution.\
For example, consider the following loop:
```
for i = 1 to bignumber step 1
    A(i)
    B(i)
    C(i)
end
```
In this example, let A(i), B(i), C(i) be instructions, each operating on data i, that are dependent on each other: A(i) must complete before B(i) can start. For examples, A could load data from memory into a register, B could perform some arithmetic operation on the data, and C could store the data back into memory. However, let there be no dependence between operations for different values of i: A(2) can begin fefore A(1) finishes. \
Without software pipelining, the operations execute in the following sequence:
```
A(1) B(1) C(1) A(2) B(2) C(2) A(3) B(3) C(3) ...
```
Assume that each instruction takes 3 clock cycles to complete (ignore for the moment the cost of the looping control flow). Also assume that an instruction can be dispatched every cycle, as long as it has no dependencies on an instruction that is already executing. Inthe unpipelined case, each iteration thus takes 9 cycles to complete: 3 clock cycles for A(1), 3 clock cycles for B(1), and 3 clock cycles for C(1). \
Now consider the following sequence of instructions with software pipelining:
```
A(1) A(2) A(3) B(1) B(2) B(3) C(1) C(2) C(3) ...
```
It can be easily verified that an instruction can be dispatched each cycle, which means that the same 3 iterations can be executed in a total of 9 cycles, giving an average of 3 cycles per iteration. \
The implementation of software pipelining is showed below:
```
for i = 1 to (bignumber - 2) step 3
    A(i)
    A(i+1)
    A(i+2)
    B(i)
    B(i+1)
    B(i+2)
    C(i)
    C(i+1)
    C(i+2)
end
```

## 2.5 Thread-Level Parallelism (TLP)
Ref wiki: https://en.wikipedia.org/wiki/Task_parallelism. \
Also known as Task Parallelism, is a form of parallelization of computer code across multiple processors in parallel computing enviroments. \
For example:
```
program:
...
if CPU="a" then
    do task "A"
else if CPU="b" then
    do task "B"
end if
...
end program
```
## 2.6 Data-Level Parallelism (DLP)
Ref wiki: https://en.wikipedia.org/wiki/Data_parallelism. \
Also known as Data Parallelism, is parallelization across multiple processors in parallel computing enviroments. It focuses on distributing the data across different nodes, which operate on the data in parallel. \
In a multiprocessor system executing a single set of instructions (SIMD), data parallelism is achieved when each processor performs the same task on different pieces of distributed data. \
An example of DLP implemented using OpenMP is showed below:
```
// Matrix multiplication in parallel
#pragma omp parallel for schedule(dynamic, 1) collapse(2)
for (i = 0; i < row_length_A; i++)
{
    for (k = 0; k < column_length_B; k++)
    {
        sum = 0;
        for (j = 0; j < column_length_A; j++)
        {
            sum += A[i][j] * B[j][k];
        }
        C[i][k] = sum;
    }
}
```

# 3. Paper Content
## 3.1 Main Contribution
1. We present a novel 3.5D blocking algorithm that performs a 2.5D spatial blocking and an additional temporal blocking of the input grid into on-chip memory.
2. By making SC and LBM compute bound, our implementation effectively utilizes the available thread- and data-level parallelism on modern processors.
3. We present a flexible load-balancing scheme that distributes the grid elements equally amongst the available threads.
4. We obtain the fastest implementation of 7-point stencil and LBM on a single-socket Intel Core i7 CPU for both single- and double-precision inputs.
5. On Nvidia GTX 285 GPU, our 7-point stencil for single-precision inputs is 1.8X faster than previously reported numbers.

## 3.2 Related Work
1. Datta et al propose an tuto-tuning approach for SC to select appropriate blocking parameters for several architectures. -- Datta, Kaushik. "Auto -tuning stencil codes for cache-based multicore platforms." Dissertations & Theses - Gradworks (2009).
2. Williams et al use an auto-tuning approach to optimize an LBM variant. -- Williams, Samuel, et al. "Optimization of a lattice Boltzmann computation on state-of-the-art multicore platforms." Journal of Parallel & Distributed Computing 69.9(2009):762-777.

## 3.3 Important Term
### 3.3.1 LBM
For LBM, the neighboring velocity vectors must be stored in structure-of-arrays format to enable SIMD processing without gathering data from disjoint regions of memory.

### 3.3.2 Analysis of SC
A 7-point stencil operation can be represented by the following equation:
```math
B_{x, y, z}(t + 1) = \alpha A_{x, y, z}(t) + \beta (A_{x - 1, y, z}(t) + A_{x + 1, y, z}(t) + A_{x, y - 1, z}(t) + A_{x, y+1, z}(t) + A_{x, y, z - 1}(t) + A_{x, y, z + 1}(t))
```
A destination grid $ B_{x, y, z} $ for time step $ t + 1 $ is updated with a stencil that fetches a grid point from 7 points of a source array $ A $ for time step $ t: A_{x, y, z} $ and its 6 neighbors in x-1, x+1, y-1, y+1, z-1, z+1 directions.


# New Vocabulary and Phrase
## State-of-the-Art
The phrase is used to decribe something which is the most advanced and at the highest level. \
For examples, blockchain is an state-of-the-art Internet technology.

## to This End
A phrase that express for doing something. \
For example, he likes millitary aircraft, to this end, he joined the airforce.

# 1. Annotated Biliography
Nguyen, Anthony, et al. "3.5-D Blocking Optimization for Stencil Computations on Modern CPUs and GPUs." ACM/IEEE International Conference for High PERFORMANCE Computing, Networking, Storage and Analysis IEEE Computer Society, 2010:1-13. \
\
This article present a new 3.5-dimension blocking algorithm which performs 2.5-dimension spatial and 1-dimension temporal blocking of the input grid in on-chip memory for both CPUs and GPUs. The algorithm is amenable to both TLP and DLP, and scales near-linearly with the SIMD width and multiple-cores.

# 2. Related Concept
## 2.1 Stencil Computation (SC)
Stencil computation sweeps over a spatial grid over multiple time steps to perform nearest-neighbor computations.

## 2.2 Compute Bound
Wiki: https://en.wikipedia.org/wiki/CPU-bound. \
A computer is CPU-bound when the time for it to complete a task is determined principally by the speed of the centrl processor. \
Extension: In computer science, X-bound is the concept that performance is limited that can't be improved due to X.

## 2.3 Tranlation Look aside Buffer (TLB)
Memory instructions must go through a virtual-to-physical address translation, which is in the critical path of program execution. To improve translation speed, a TLB is used to cache virtual-to-physical translation of most frequently accessed pages. if the translation is not found in the TLB, processor pipeline stalls util the TLB miss is served.

## 2.4 Software Pipelining
Wiki: https://en.wikipedia.org/wiki/Software_pipelining. \
Software pipelining is a technique used to optimize loops, it is a type of out-of-order execution.\
For example, consider the following loop:
```
for i = 1 to bignumber step 1
    A(i)
    B(i)
    C(i)
end
```
In this example, let A(i), B(i), C(i) be instructions, each operating on data i, that are dependent on each other: A(i) must complete before B(i) can start. For examples, A could load data from memory into a register, B could perform some arithmetic operation on the data, and C could store the data back into memory. However, let there be no dependence between operations for different values of i: A(2) can begin fefore A(1) finishes. \
Without software pipelining, the operations execute in the following sequence:
```
A(1) B(1) C(1) A(2) B(2) C(2) A(3) B(3) C(3) ...
```
Assume that each instruction takes 3 clock cycles to complete (ignore for the moment the cost of the looping control flow). Also assume that an instruction can be dispatched every cycle, as long as it has no dependencies on an instruction that is already executing. Inthe unpipelined case, each iteration thus takes 9 cycles to complete: 3 clock cycles for A(1), 3 clock cycles for B(1), and 3 clock cycles for C(1). \
Now consider the following sequence of instructions with software pipelining:
```
A(1) A(2) A(3) B(1) B(2) B(3) C(1) C(2) C(3) ...
```
It can be easily verified that an instruction can be dispatched each cycle, which means that the same 3 iterations can be executed in a total of 9 cycles, giving an average of 3 cycles per iteration. \
The implementation of software pipelining is showed below:
```
for i = 1 to (bignumber - 2) step 3
    A(i)
    A(i+1)
    A(i+2)
    B(i)
    B(i+1)
    B(i+2)
    C(i)
    C(i+1)
    C(i+2)
end
```

## 2.5 Thread-Level Parallelism (TLP)
Wiki: https://en.wikipedia.org/wiki/Task_parallelism. \
Also known as Task Parallelism, is a form of parallelization of computer code across multiple processors in parallel computing enviroments. \
For example:
```
program:
...
if CPU="a" then
    do task "A"
else if CPU="b" then
    do task "B"
end if
...
end program
```
## 2.6 Data-Level Parallelism (DLP)
Wiki: https://en.wikipedia.org/wiki/Data_parallelism. \
Also known as Data Parallelism, is parallelization across multiple processors in parallel computing enviroments. It focuses on distributing the data across different nodes, which operate on the data in parallel. \
In a multiprocessor system executing a single set of instructions (SIMD), data parallelism is achieved when each processor performs the same task on different pieces of distributed data. \
An example of DLP implemented using OpenMP is showed below:
```c
// Matrix multiplication in parallel
#pragma omp parallel for schedule(dynamic, 1) collapse(2)
for (i = 0; i < row_length_A; i++)
{
    for (k = 0; k < column_length_B; k++)
    {
        sum = 0;
        for (j = 0; j < column_length_A; j++)
        {
            sum += A[i][j] * B[j][k];
        }
        C[i][k] = sum;
    }
}
```

## 2.7 Cache-Coherence
Wiki: https://en.wikipedia.org/wiki/Cache_coherence. \
Cache-coherence is the uniformity of shared resource data that ends up stored in multiple local caches. \
\
coherence cache: \
![coherence cache](https://upload.wikimedia.org/wikipedia/commons/thumb/8/88/Coherent.gif/220px-Coherent.gif) \
incoherence cache: \
![incoherence cache](https://upload.wikimedia.org/wikipedia/commons/thumb/e/ea/Non_Coherent.gif/220px-Non_Coherent.gif)

# 3. Vocabulary
## State-of-the-Art
This phrase is used to decribe something which is the most advanced and at the highest level. \
For examples, blockchain is an state-of-the-art Internet technology.

## to This End
A phrase that express for doing something. \
For example, he likes millitary aircraft, to this end, he joined the airforce.

## amenable
Easy to control.
